# Web Crawler ä»å®æˆ˜åˆ°åŸºç¡€

>  Any content that can be viewed on a webpage can be scraped. Period.



> ç‰ˆæƒå½’ä½œè€…æ‰€æœ‰ï¼Œä»»ä½•å½¢å¼è½¬è½½è¯·è”ç³»ä½œè€…ã€‚
> ä½œè€…ï¼šastrojacobliï¼ˆæ¥è‡ªè±†ç“£ï¼‰
> æ¥æºï¼šhttps://www.douban.com/note/749118764/
>
> ä¸–ç•Œå°±å¥½åƒä¸€ä¸ªçŸ›ç›¾ç»“åˆä½“ï¼Œç½‘ç»œä¸–ç•Œä¹Ÿä¸ä¾‹å¤–ã€‚ä¸€å¸®äººæ‹¥æœ‰ä¿¡æ¯ï¼Œä»–ä»¬çš„å·¥ä½œæ˜¯åœ¨å±•ç¤ºä¿¡æ¯çš„åŒæ—¶åŠ å¯†ä¿¡æ¯ï¼›å¦ä¸€å¸®äººæ²¡æœ‰ä¿¡æ¯ï¼Œéœ€è¦ä¿¡æ¯ï¼Œæ‰€ä»¥ä»–ä»¬æƒ³å°½åŠæ³•æŠ“å–å’Œç ´è§£ä¿¡æ¯ã€‚
>
> ä¸¾ä¸ªä¾‹å­ï¼šè±†ç“£æ‹¥æœ‰ç”¨æˆ·ï¼Œç”¨æˆ·å–œæ¬¢ç”µå½±ï¼Œäºæ˜¯ç”¨æˆ·å°†ä»–ä»¬å–œæ¬¢çš„ç”µå½±ä¿¡æ¯æä¾›ç»™è±†ç“£ï¼Œè±†ç“£æ”¶åˆ°ä¿¡æ¯åæŠŠè¿™äº›ä¿¡æ¯poåœ¨ç½‘é¡µä¸Šã€‚ç„¶è€Œæœ‰äº›äººå¥½å¥‡æŸä¸ªäººçœ‹è¿‡ä»€ä¹ˆç”µå½±ï¼Œè€Œä»–èƒ½å¾—åˆ°çš„åªæ˜¯é‚£ä¸ªç½‘é¡µï¼Œå› æ­¤æ€ä¹ˆæŠŠä¿¡æ¯ç»™æŠ“å–ä¸‹æ¥å°±æ˜¯ä¸ªé—®é¢˜ï¼ˆç½‘é¡µçš„ç†µæ˜¾ç„¶å¤§äºæŠ“å–åçš„ä¿¡æ¯çš„ç†µï¼Œå› æ­¤ä½ éœ€è¦ç»™è¿™äº›ä¿¡æ¯æ³¨å…¥èƒ½é‡ï¼Œè¿™äº›èƒ½é‡åŒ…æ‹¬ä½†ä¸é™äºä½ ç”µè„‘çš„ç”µè´¹ã€ä½ åƒçš„é¥­è¿˜æœ‰è·Ÿå¥³æœ‹å‹å–å…³å­æ—¶å€™å’½çš„å£æ°´ï¼‰ã€‚
>
> è¿™ä¸ªæŠ€æœ¯å°±æ˜¯ç½‘ç»œçˆ¬è™«ï¼›ä½†å®¹æ˜“æƒ³åˆ°ï¼Œåœ¨ç½‘é¡µå‘æ˜ä¹‹å‰ï¼Œåœ¨ä¿¡æ¯çˆ†ç‚¸ä¹‹å‰ï¼Œæ²¡æœ‰çˆ¬è™«è¿™ç§ç©æ„ã€‚æ‰€ä»¥å•Šï¼Œè¿˜æ˜¯only you can conquer time...
>
> é‚£è¿™ç©æ„æœ‰å•¥å­ç”¨å‘¢ï¼Ÿå°±æˆ‘ç²—æµ…çš„ç†è§£ï¼Œä¸¾ä¸ªä¾‹å­çš„è¯ï¼Œè¿˜æ˜¯ä¸»è¦è·Ÿäººç›¸å…³çš„é—®é¢˜éœ€è¦çˆ¬è™«ï¼ˆå› ä¸ºè·Ÿäººæ²¡å…³ç³»çš„äº‹å„¿ä¹Ÿä¸ä¼špoåœ¨ç½‘ç«™ä¸Šï¼‰ã€‚äººç±»çš„è´­ç‰©åå¥½æ˜¯ä»€ä¹ˆï¼Ÿç¤¾äº¤ç½‘ç»œåå¥½æ˜¯ä»€ä¹ˆï¼ˆè¿™ä¸ªé—®é¢˜ç‰µæ‰¯åˆ°å›¾è®ºå’Œå›¾å­¦ä¹ ï¼‰ï¼ŸæŸä¸ªäººçš„è§‚å½±åå¥½æ˜¯ä»€ä¹ˆï¼Ÿäº‘äº‘ã€‚
>
> å…·ä½“å®ç°èµ·æ¥ï¼Œé“ç†ä¸Šè®²éå¸¸å®¹æ˜“ï¼šç½‘é¡µæ˜¯äººå†™çš„ï¼Œhtmlæ ¼å¼ä¸‹è½½ä¸‹æ¥ï¼Œèƒ½çœ‹è§çš„ä¿¡æ¯éƒ½åœ¨æ–‡ä»¶é‡Œï¼Œåªè¦æŠŠéœ€è¦çš„ä¿¡æ¯å–å‡ºæ¥å°±è¡Œäº†ã€‚ä»Šå¤©å¸¦ç»™å„ä½çœ‹å®˜çš„ç¦éŸ³æ˜¯ï¼ŒPythonå·²ç»æœ‰åˆ«äººå¼€å‘å¥½çš„å®Œå¤‡å·¥å…·å¯ä»¥ä½¿ç”¨ï¼Œç›®å‰æœ€å¤šç”¨çš„æ˜¯scrapyã€‚ä½¿ç”¨èµ·æ¥éå¸¸æ–¹ä¾¿ï¼Œå‘Šè¯‰å®ƒä»å“ªé‡Œå¼€å§‹çˆ¬ï¼Œçˆ¬ä»€ä¹ˆå†…å®¹ï¼Œå¦‚ä½•ç¿»é¡µï¼Œä¿å­˜æˆä»€ä¹ˆæ ¼å¼å°±å¯ä»¥äº†ã€‚ä½†æ˜¯è¿˜æ˜¯å¾—å…ˆçŸ¥é“ä¸€ç‚¹htmlå’Œcssçš„çŸ¥è¯†ã€‚

çˆ¬è™«çš„æœ¬è´¨æ˜¯ä»€ä¹ˆï¼Ÿ



## è±†ç“£ç”µå½± Top250

å·¥å…·ï¼š`scrapy`ï¼Œå‘½ä»¤è¡Œå·¥å…·ã€‚

`pip install -i https://pypi.tuna.tsinghua.edu.cn/simple scrapy`

ç½‘ç«™ï¼šhttps://movie.douban.com/top250

ä½¿ç”¨å¸®åŠ©ï¼š`scrapy -h`



### 1. æ–°å»ºscrapyé¡¹ç›®

`scrapy startproject douban`, å¯Ÿçœ‹æ–‡ä»¶ç»“æ„

### 2. å°è¯•ç‰›åˆ€ï¼Ÿ

`scrapy shell https://movie.douban.com/top250`

`view(response)`

ä¸è¡Œï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ

>  åœ¨HTTPä¸­ï¼ŒUser-Agentå­—ç¬¦ä¸²é€šå¸¸è¢«ç”¨æ–¼[å†…å®¹åå•†](https://zh.wikipedia.org/wiki/å†…å®¹åå•†)ï¼Œè€ŒåŸå§‹æœåŠ¡å™¨ä¸ºè¯¥å“åº”é€‰æ‹©é€‚å½“çš„å†…å®¹æˆ–æ“ä½œå‚æ•°ã€‚ä¾‹å¦‚ï¼ŒUser-Agentå­—ç¬¦ä¸²å¯èƒ½è¢«ç½‘ç»œæœåŠ¡å™¨ç”¨ä»¥åŸºäºç‰¹å®šç‰ˆæœ¬çš„å®¢æˆ·ç«¯è½¯ä»¶çš„å·²çŸ¥åŠŸèƒ½é€‰æ‹©é€‚å½“çš„å˜ä½“ã€‚
>
> é€šè¿‡ä½¿ç”¨[robots.txt](https://zh.wikipedia.org/wiki/Robots.txt)æ–‡ä»¶çš„å¯ä»¥è¨­å®š[ç½‘ç»œæŠ“å–å·¥å…·](https://zh.wikipedia.org/w/index.php?title=ç½‘ç»œæŠ“å–å·¥å…·&action=edit&redlink=1)å°ç¶²ç«™çš„éƒ¨åˆ†è¨ªå•èˆ‡å¦ï¼Œè€Œå…¶è¨­å®šæ¨™æº–ä¹‹ä¸€å°±æ˜¯ç”¨æˆ·ä»£ç†å­—ç¬¦ä¸²ã€‚æ›å¥è©±èªªï¼Œè—‰ç”±[robots.txt](https://zh.wikipedia.org/wiki/Robots.txt)æ–‡ä»¶çš„è¨­å®šï¼Œå¯ä»¥è®“ç¶²ç«™ä¸èƒ½è¢«ç‰¹å®šçš„ç€è¦½å™¨è¨ªå•ã€‚



`settings.py`ä¸­ï¼š

```py
ROBOTSTXT_OBEY = False
```

```py
USER_AGENT = 'Mozilla/5.0 (iPhone; CPU iPhone OS 5_1 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9B179 Safari/7534.48.3'
```

```py
USER_AGENT = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36'
```



### 3. çˆ¬è™«çš„æœ¬è´¨æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆä¸æ˜¯å¤è¯»æœºï¼‰

ä½¿ç”¨Safariå¼€å‘è€…å·¥å…·ï¼šinspect elementsï¼Œè§‚å¯Ÿä¹‹ã€‚

æœ¬è´¨å°±æ˜¯æŠŠè¿™äº›codeé‡Œçš„ç‰¹æ®Šå­—æ®µè¯†åˆ«å‡ºæ¥ï¼



### 4. å°è¯•ç‰›åˆ€ï¼

`scrapy shell https://movie.douban.com/top250`

`view(response)`

ä½¿ç”¨Safariå¼€å‘è€…å·¥å…·ï¼šinspect elementsï¼Œå¹¶è§‚å¯Ÿã€‚

è¿™æ˜¯ä¸€ä¸ªæŒ¨ä¸ªå®éªŒçš„è¿‡ç¨‹ï¼ï¼ï¼åƒä¸‡ä¸è¦ä»¥ä¸ºä¸€æ¬¡å¯ä»¥å†™å¥½ï¼

```python
movie = response.css('ol.grid_view li')[0] # Selector

movie.css('div.item').getall()

movie.css('div.item div.pic a').attrib['href']

movie.css('div.item div.hd a').attrib['href']

movie.css('div.item div.hd span.title').getall()
movie.css('div.item div.hd span.title::text')
movie.css('div.item div.hd span.title::text').getall()

movie.css('div.item div.bd p::text').getall()
movie.css('div.item div.bd div.star span.rating_num::text').getall()
movie.css('div.item div.bd div.star span::text').getall()

movie.css('.bd p.quote::text').getall()
movie.css('.bd p.quote ::text').getall()
movie.css('.bd p.quote span.inq::text').getall()
movie.css('.bd p.quote span.inq::text').get()
```



ç°åœ¨æˆ‘ä»¬æ˜ç™½äº†æ€ä¹ˆä¿¡æ¯è—åœ¨ç½‘é¡µä½•å¤„ï¼Œä½†æ˜¯å¦‚ä½•å¤„ç†è¿™äº›ä¿¡æ¯å‘¢ï¼Ÿå¦‚ä½•æŠŠä»–ä»¬å¼„å¾—æ›´æ•´æ´ï¼Ÿ

ä¸¾ä¸ªğŸŒ°ï¼

```python
name_list = movie.css('div.item div.hd span.title::text').getall()
chn_name = name_list[0]
eng_name = name_list[1].strip('\xa0/\xa0')

score_num = movie.css('div.item div.bd div.star span::text').getall()[1].strip('äººè¯„ä»·')

quote = movie.css('div.item div.bd p.quote span.inq::text').get()
```

è¯·å®Œæˆå‰©ä¸‹çš„ (ä¸ä¼šçš„ç•™ç€ğŸ˜›)ï¼š

```python
ranking =  # æ’ç¬¬å‡ å
score = # è¯„åˆ†
director = # å¯¼æ¼”æ˜¯è°
year = # å“ªå¹´çš„ç”µå½±
url = # ç”µå½±çš„é“¾æ¥
```

ä¸‹è¯¾ä¼‘æ¯30min



### 5. æ‰¹é‡ç”Ÿäº§

- å»ºç«‹items

  åœ¨item.pyé‡Œï¼š

  ```python
  class DoubanItem(scrapy.Item):
      # define the fields for your item here like:
      # name = scrapy.Field()
      # æ’å
      ranking = scrapy.Field()
      # ç”µå½±åç§°
      chn_name = scrapy.Field()
      eng_name = scrapy.Field()
      # è¯„åˆ†
      score = scrapy.Field()
      # è¯„è®ºäººæ•°
      score_num = scrapy.Field()
      # Director
      director = scrapy.Field()
      # Year of Production
      year = scrapy.Field()
      # URL
      url = scrapy.Field()
      # Quote
      quote = scrapy.Field()
      pass
    
  ```

- å»ºç«‹spider

  `cd douban/spider`

  `touch douban_spider.py`

  ```python
  from douban.items import DoubanItem
  import scrapy
  import logging
  import numpy as np
  
  # spider class
  class DoubanMovieTop250Spider(scrapy.Spider):
      name = 'douban250' # name of this spider
      start_urls = ['https://movie.douban.com/top250']
      
      def parse(self, response):
          item = DoubanItem()
          movies = response.css("ol.grid_view li")
          for movie in movies:
            	## 
              item['score'] = float(movie.css(".star span.rating_num::text").get())
              ##
              yield item
          ## ç¿»é¡µï¼
          next_page = response.css("div.paginator span.next a::attr(href)").get()
          if next_page is not None:
              yield response.follow(next_page, callback=self.parse)
  ```

- è®©spiderçˆ¬ï¼

  é€€å‡ºåˆ°æœ€åˆçš„doubanæ–‡ä»¶å¤¹

  `scrapy crawl douban250 -o douban_movie.csv`

- åœ¨pandasé‡Œè¯»å–æ–‡ä»¶

  `pd.read_csv('douban_movie.csv')`

  









## çˆ¬è™«



https://www.analyticsvidhya.com/blog/2017/07/web-scraping-in-python-using-scrapy/



XPath:

https://www.w3.org/TR/xpath/all/

https://docs.scrapy.org/en/latest/topics/selectors.html#topics-selectors

http://zvon.org/comp/r/tut-XPath_1.html

http://plasmasturm.org/log/xpath101/



Scrapy on notebook: https://www.jitsejan.com/using-scrapy-in-jupyter-notebook.html



https://monkeylearn.com/blog/filtering-startup-news-machine-learning/



Exercise: [Regular Expression](https://github.com/ziishaned/learn-regex)



Awesone-spider: https://github.com/facert/awesome-spider

æœ‰è¶£çš„Pythonçˆ¬è™«å’Œæ•°æ®åˆ†æå°é¡¹ç›®: https://github.com/Alfred1984/interesting-python

Pythonå…¥é—¨ç½‘ç»œçˆ¬è™«ä¹‹ç²¾åç‰ˆ: https://github.com/lining0806/PythonSpiderNotes